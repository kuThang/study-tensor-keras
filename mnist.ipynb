{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "[5 0 4]\n",
      "(48000, 28, 28)\n",
      "(12000, 28, 28)\n",
      "[4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train[0:3])\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=99)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_train[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 132us/step - loss: 0.2410 - acc: 0.9293 - val_loss: 0.1268 - val_acc: 0.9625\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.1062 - acc: 0.9675 - val_loss: 0.1016 - val_acc: 0.9685\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 7s 155us/step - loss: 0.0765 - acc: 0.9760 - val_loss: 0.0856 - val_acc: 0.9735\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.0587 - acc: 0.9815 - val_loss: 0.0698 - val_acc: 0.9803\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 8s 156us/step - loss: 0.0448 - acc: 0.9855 - val_loss: 0.0728 - val_acc: 0.9786\n",
      "Wall time: 36.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "fit = model.fit(x_train, y_train, epochs=5, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 0.0207 - acc: 0.9934\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 20s 336us/step - loss: 0.0158 - acc: 0.9946\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 20s 327us/step - loss: 0.0163 - acc: 0.9948\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 18s 292us/step - loss: 0.0157 - acc: 0.9946\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 22s 370us/step - loss: 0.0159 - acc: 0.9947\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, 10)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "fit = model.fit(x_train, y_train_one_hot, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28, 28,1)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.1162 - acc: 0.9637\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0388 - acc: 0.9881\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0239 - acc: 0.9925\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0149 - acc: 0.9948\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0104 - acc: 0.9967\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, 10)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "fit = model.fit(x_train, y_train_one_hot, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model\n",
    "All layers must be defined in __init__() and run order in call()\n",
    "\n",
    "<mark>TODO</mark>: what is compute_output_shape() -> change output size if nescessary. See **Define layer > Flatten layer** for more information\n",
    "\n",
    "\"[In case your layer modifies the shape of its input, you should specify here the shape transformation logic](https://keras.io/layers/writing-your-own-keras-layers/). This allows Keras to do automatic shape inference.\" (from keras page) - **mean, not necessary ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        self.flatten_1= layers.Flatten(input_shape=(28, 28))\n",
    "        self.dense_1 = layers.Dense(512, activation='relu')\n",
    "        self.dropout_1 = layers.Dropout(0.2)\n",
    "        self.dense_2 = layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.flatten_1(inputs)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        return self.dense_2(x)\n",
    "    \n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         shape = tf.TensorShape(input_shape).as_list()\n",
    "#         shape[-1] = self.num_classes\n",
    "#         return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 9s 180us/step - loss: 0.3486 - acc: 0.8940\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 123us/step - loss: 0.1184 - acc: 0.9653\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 6s 123us/step - loss: 0.0896 - acc: 0.9750\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 6s 129us/step - loss: 0.0727 - acc: 0.9795\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 128us/step - loss: 0.0623 - acc: 0.9825\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(num_classes=10)\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "fit = model.fit(x_train, y_train, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define layer\n",
    "Define a layer is more more more difficult than Model\n",
    "\n",
    "Some notes on this:\n",
    "* Some tensorflow function takes a tensor of int (double, float ..) as argument. This means we cannot pass None ( number of sample ) to it. (See MyFlattenLayer)\n",
    "* Always define compute_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class MyFlattenLayer(layers.Layer):\n",
    "    def __init__(self, data_format=None, **kwargs):\n",
    "        self.data_format = data_format\n",
    "        super(MyFlattenLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.data_format==\"channels_first\":\n",
    "            transpose_order = [0]\n",
    "            transpose_order.extend([i for i in range(2, len(inputs.get_shape()))])\n",
    "            transpose_order.append(1)\n",
    "            inputs = tf.transpose(inputs, perm=transpose_order)\n",
    "        output_shape = self.compute_output_shape(inputs.get_shape())\n",
    "#         NOTE : Error occurred with following code, because input size is None, not a tensor of int32\n",
    "#         outputs = tf.reshape(inputs, output_shape)\n",
    "        outputs = tf.reshape(inputs, (tf.shape(inputs)[0], output_shape[1]))\n",
    "        return outputs\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = tf.TensorShape(input_shape).as_list()\n",
    "        output_shape = [input_shape[0]]\n",
    "        if all(input_shape[1:]):\n",
    "            output_shape += [np.prod(input_shape[1:])]\n",
    "        else :\n",
    "            output_shape += [None]\n",
    "        return tf.TensorShape(output_shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(MyFlattenLayer, self).get_config()\n",
    "        base_config['data_format'] = self.data_format\n",
    "        return base_config\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 0.3838 - acc: 0.8851 - val_loss: 0.1666 - val_acc: 0.9512\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1319 - acc: 0.9612 - val_loss: 0.1310 - val_acc: 0.9616\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0951 - acc: 0.9724 - val_loss: 0.1075 - val_acc: 0.9681\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.0746 - acc: 0.9779 - val_loss: 0.1002 - val_acc: 0.9711\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0613 - acc: 0.9819 - val_loss: 0.0935 - val_acc: 0.9742\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    MyFlattenLayer(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "fit = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(layers.Layer):\n",
    "    def __init__(self, output_dim, activation, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "        super(MyDenseLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[1], self.output_dim)).as_list()\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                  shape=shape,\n",
    "                                  initializer='uniform', \n",
    "                                      dtype=tf.float32,\n",
    "                                  trainable=True)\n",
    "        super(MyDenseLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        y = layers.Activation(self.activation)(tf.matmul(inputs, self.kernel))\n",
    "        return y\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(MyDenseLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        base_config['activation'] = self.activation\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 8s 157us/step - loss: 0.4660 - acc: 0.8647 - val_loss: 0.1984 - val_acc: 0.9421\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 0.1606 - acc: 0.9539 - val_loss: 0.1389 - val_acc: 0.9597\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.1145 - acc: 0.9669 - val_loss: 0.1181 - val_acc: 0.9658\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.0908 - acc: 0.9735 - val_loss: 0.1087 - val_acc: 0.9697\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 112us/step - loss: 0.0741 - acc: 0.9784 - val_loss: 0.1087 - val_acc: 0.9706\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    MyFlattenLayer(),\n",
    "    MyDenseLayer(128, 'relu'),\n",
    "    MyDenseLayer(10, 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "fit = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv_tesseract",
   "language": "python",
   "name": "pyenv_tesseract"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
